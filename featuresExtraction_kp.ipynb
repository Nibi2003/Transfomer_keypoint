{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nibi2003/Transfomer_keypoint/blob/main/featuresExtraction_kp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK3lqdk-GPj6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import cv2\n",
        "import random\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, experimental, GlobalAveragePooling3D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import callbacks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO5008U9ZDu6",
        "outputId": "5e1a8377-760b-4a83-8ce8-59cfc7dc1089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Nibi2003/Transfomer_keypoint.git\n"
      ],
      "metadata": {
        "id": "Ldp4te2QEc34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab7231e-3943-4eb4-e98b-9fcf8a0ce969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Transfomer_keypoint'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 148 (delta 21), reused 84 (delta 12), pack-reused 46\u001b[K\n",
            "Receiving objects: 100% (148/148), 148.25 MiB | 40.71 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Análise da base"
      ],
      "metadata": {
        "id": "q6UW4tmhpDCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "data_dir = '/content/Transfomer_keypoint/MediaPipe/treino'\n",
        "\n",
        "keypoints_list = []\n",
        "labels_list = []\n",
        "\n",
        "for class_folder in os.listdir(data_dir):\n",
        "    class_path = os.path.join(data_dir, class_folder)\n",
        "\n",
        "    for file_path in glob.glob(os.path.join(class_path, '*.npy')):\n",
        "        keypoints = np.load(file_path, allow_pickle=True)\n",
        "        keypoints_list.append(keypoints)\n",
        "        labels_list.append(int(class_folder))\n",
        "\n",
        "keypoints_array = np.array(keypoints_list)\n",
        "labels_array = np.array(labels_list)"
      ],
      "metadata": {
        "id": "ALuCzw6NEa03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_dir = '/content/Transfomer_keypoint/MediaPipe/teste'\n",
        "\n",
        "test_keypoints_list = []\n",
        "test_labels_list = []\n",
        "\n",
        "for class_folder in os.listdir(test_data_dir):\n",
        "    class_path = os.path.join(test_data_dir, class_folder)\n",
        "\n",
        "    for file_path in glob.glob(os.path.join(class_path, '*.npy')):\n",
        "        keypoints = np.load(file_path, allow_pickle=True)\n",
        "        test_keypoints_list.append(keypoints)\n",
        "        test_labels_list.append(int(class_folder))\n",
        "\n",
        "test_keypoints_array = np.array(test_keypoints_list)\n",
        "test_labels_array = np.array(test_labels_list)\n"
      ],
      "metadata": {
        "id": "r2YBmnQZ550a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keypoints_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZsNN3G95nkb",
        "outputId": "8d92072a-3139-4055-d755-a8250c4cfcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22, 900, 33, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_keypoints_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtNtk4ZZ57IL",
        "outputId": "3127306e-e614-467c-d02a-8cc26124a916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 900, 33, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(keypoints_array[0][32])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nELqn3zmDosS",
        "outputId": "36164732-b3d8-447d-dd79-fa80483cddf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5771201252937317 0.7042163610458374]\n",
            " [0.6001623272895813 0.7117573022842407]\n",
            " [0.6086949706077576 0.7101182341575623]\n",
            " [0.6169539093971252 0.7081056237220764]\n",
            " [0.5789942145347595 0.715644121170044]\n",
            " [0.5720163583755493 0.7161332964897156]\n",
            " [0.5636076331138611 0.716242790222168]\n",
            " [0.6284133791923523 0.690328061580658]\n",
            " [0.5513102412223816 0.7081841826438904]\n",
            " [0.5822604894638062 0.6886199116706848]\n",
            " [0.5594426393508911 0.6923927068710327]\n",
            " [0.6824284195899963 0.6101470589637756]\n",
            " [0.47325894236564636 0.6693674325942993]\n",
            " [0.6031072735786438 0.5773155689239502]\n",
            " [0.555853009223938 0.7344653010368347]\n",
            " [0.563897967338562 0.6345265507698059]\n",
            " [0.6769514679908752 0.8265455961227417]\n",
            " [0.5603675842285156 0.6450223326683044]\n",
            " [0.6883518695831299 0.8521827459335327]\n",
            " [0.5449455380439758 0.6560186743736267]\n",
            " [0.6940045356750488 0.8514536619186401]\n",
            " [0.54421466588974 0.6516786217689514]\n",
            " [0.6926397085189819 0.8373383283615112]\n",
            " [0.4616260528564453 0.37606844305992126]\n",
            " [0.3313409388065338 0.40678760409355164]\n",
            " [0.5646642446517944 0.3853492736816406]\n",
            " [0.28398868441581726 0.3995596170425415]\n",
            " [0.5997402667999268 0.33043262362480164]\n",
            " [0.17086659371852875 0.3693741261959076]\n",
            " [0.6037942171096802 0.32827991247177124]\n",
            " [0.12285160273313522 0.3417778015136719]\n",
            " [0.6107507348060608 0.29802292585372925]\n",
            " [0.09552169591188431 0.2944416105747223]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def verificar_keypoints_nao_detectados(keypoints_array):\n",
        "    total_videos, total_quadros, total_keypoints, _ = keypoints_array.shape\n",
        "\n",
        "    keypoints_ausentes = 0\n",
        "\n",
        "    for video_idx in range(total_videos):\n",
        "        for quadro_idx in range(total_quadros):\n",
        "            for kp_idx in range(total_keypoints):\n",
        "                keypoint = keypoints_array[video_idx, quadro_idx, kp_idx]\n",
        "\n",
        "                # Verificar se o keypoint não foi detectado\n",
        "                if keypoint is None:\n",
        "                    keypoints_ausentes += 1\n",
        "\n",
        "    return keypoints_ausentes\n",
        "\n",
        "# Verificar keypoints não detectados em todos os vídeos\n",
        "keypoints_ausentes_total = verificar_keypoints_nao_detectados(keypoints_array)\n",
        "\n",
        "print(\"Total de keypoints não detectados:\", keypoints_ausentes_total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu1sD7oE3amy",
        "outputId": "7900a898-be9b-4527-b04f-948ac4c4c60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de keypoints não detectados: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def verificar_keypoints_nao_detectados_e_zeros(keypoints_array):\n",
        "    total_videos, total_quadros, total_keypoints, _ = keypoints_array.shape\n",
        "\n",
        "    keypoints_ausentes = 0\n",
        "    keypoints_zeros = 0\n",
        "\n",
        "    for video_idx in range(total_videos):\n",
        "        for quadro_idx in range(total_quadros):\n",
        "            for kp_idx in range(total_keypoints):\n",
        "                keypoint = keypoints_array[video_idx, quadro_idx, kp_idx]\n",
        "\n",
        "                # Verificar se o keypoint não foi detectado\n",
        "                if keypoint is None:\n",
        "                    keypoints_ausentes += 1\n",
        "                elif keypoint.tolist() == [0.0, 0.0]:\n",
        "                    keypoints_zeros += 1\n",
        "\n",
        "    return keypoints_ausentes, keypoints_zeros\n",
        "\n",
        "# Verificar keypoints não detectados e zeros em todos os vídeos\n",
        "keypoints_ausentes_total, keypoints_zeros_total = verificar_keypoints_nao_detectados_e_zeros(keypoints_array)\n",
        "\n",
        "print(\"Total de keypoints não detectados:\", keypoints_ausentes_total)\n",
        "print(\"Total de keypoints com coordenadas [0.0, 0.0]:\", keypoints_zeros_total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7TVB55kC8Lg",
        "outputId": "b5f319c8-719f-4e3b-b779-a4f62ae44315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de keypoints não detectados: 0\n",
            "Total de keypoints com coordenadas [0.0, 0.0]: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def verificar_coordenadas_nao_nulas(keypoints_array):\n",
        "    total_videos, total_quadros, total_keypoints, _ = keypoints_array.shape\n",
        "\n",
        "    for video_idx in range(total_videos):\n",
        "        for quadro_idx in range(total_quadros):\n",
        "            for kp_idx in range(total_keypoints):\n",
        "                keypoint = keypoints_array[video_idx, quadro_idx, kp_idx]\n",
        "\n",
        "                # Verificar se o keypoint é None ou se alguma coordenada é zero\n",
        "                if keypoint is None or any(coord == 0.0 for coord in keypoint):\n",
        "                    print(f\"Coordenadas nulas encontradas no vídeo {video_idx}, quadro {quadro_idx}, keypoint {kp_idx}\")\n",
        "\n",
        "    print(\"Verificação concluída.\")\n",
        "\n",
        "# Verificar se todas as coordenadas são diferentes de zero e diferentes de None\n",
        "verificar_coordenadas_nao_nulas(keypoints_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG79YGi2C_yS",
        "outputId": "cd05debd-8bd7-4591-bb6e-1a8e44104cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verificação concluída.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_and_convert_to_float32(keypoints_array):\n",
        "    # Copiar o array para não modificar o original\n",
        "    normalized_array = keypoints_array.copy()\n",
        "\n",
        "    # Normalizar os valores para estar entre 0 e 1\n",
        "    max_val = np.max(normalized_array)\n",
        "    min_val = np.min(normalized_array)\n",
        "    normalized_array = (normalized_array - min_val) / (max_val - min_val)\n",
        "\n",
        "    # Converter para o tipo float32\n",
        "    normalized_array = normalized_array.astype(np.float32)\n",
        "\n",
        "    return normalized_array\n",
        "# Supondo que keypoints_array seja o seu array de keypoints\n",
        "keypoints_array_normalized = normalize_and_convert_to_float32(keypoints_array)\n",
        "keypoints_array_normalized_test = normalize_and_convert_to_float32(test_keypoints_array)\n"
      ],
      "metadata": {
        "id": "wZkQB5eZDw8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S3x5IoBFJK_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def calculate_distance_matrix(self, data):\n",
        "#     T, J, D = data.shape  # Extracting dimensions: Time, Joints, Dimension\n",
        "#     # Initializing the array for distance matrices\n",
        "#     distance_matrices = np.zeros((T, J, J))\n",
        "#     flattened_vectors = []\n",
        "\n",
        "#     for t in range(T):  # Iterate over each frame\n",
        "#         for i in range(J):  # Iterate over each joint\n",
        "#             for j in range(J):  # Iterate over each joint to calculate pairwise distances\n",
        "#                 distance_matrices[t, i, j] = np.linalg.norm(\n",
        "#                     data[t, i] - data[t, j])\n",
        "#         flattened_vectors.append(self.distance_feature_vector(\n",
        "#             distance_matrices[t]))\n",
        "\n",
        "#     return flattened_vectors\n",
        "\n",
        "# def distance_feature_vector(self, dist_matrix):\n",
        "#     upper_triangle = np.triu_indices(dist_matrix.shape[0], k=1)\n",
        "#     flattened_vector = dist_matrix[upper_triangle]\n",
        "#     return flattened_vector\n"
      ],
      "metadata": {
        "id": "sgCCwdtpJM-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def calculate_distance_matrix(data):\n",
        "#     T, J, D = data.shape  # Extracting dimensions: Time, Joints, Dimension\n",
        "#     # Initializing the array for distance matrices\n",
        "#     distance_matrices = np.zeros((T, J, J))\n",
        "\n",
        "#     for t in range(T):  # Iterate over each frame\n",
        "#         for i in range(J):  # Iterate over each joint\n",
        "#             for j in range(J):  # Iterate over each joint to calculate pairwise distances\n",
        "#                 distance_matrices[t, i, j] = np.linalg.norm(\n",
        "#                     data[t, i] - data[t, j])\n",
        "\n",
        "#     return distance_matrices\n",
        "\n",
        "# def distance_feature_vector(dist_matrix):\n",
        "#     upper_triangle = np.triu_indices(dist_matrix.shape[1], k=1)\n",
        "#     flattened_vector = dist_matrix[:, upper_triangle[0], upper_triangle[1]]\n",
        "#     return flattened_vector\n",
        "\n",
        "# def aplica_in_array(array):\n",
        "#     array_of_features = []\n",
        "#     for t in array:\n",
        "#         x1 = calculate_distance_matrix(t)\n",
        "#         x1 = distance_feature_vector(x1)\n",
        "#         array_of_features.append(x1)\n",
        "#     return array_of_features\n",
        "# array_of_features = aplica_in_array(keypoints_array_normalized)"
      ],
      "metadata": {
        "id": "yO0sUOyjJcz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# array_of_features_test = aplica_in_array(keypoints_array_normalized_test)"
      ],
      "metadata": {
        "id": "IbaNaP7ngEfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import os\n",
        "\n",
        "# # Verificar se o diretório existe, se não, criá-lo\n",
        "# output_dir = \"/content/Train_kp_features\"\n",
        "# if not os.path.exists(output_dir):\n",
        "#     os.makedirs(output_dir)\n",
        "\n",
        "# # Salvar o array no formato .npy\n",
        "# output_path = os.path.join(output_dir, \"array_of_features.npy\")\n",
        "# np.save(output_path, array_of_features)\n",
        "\n",
        "# print(f\"Array salvo em {output_path}\")\n"
      ],
      "metadata": {
        "id": "3iGK-wzDfwZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9efaeed-b85c-46af-e18d-f1926ffc4e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array salvo em /content/Train_kp_features/array_of_features.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUFMVh-K2anU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Código principal"
      ],
      "metadata": {
        "id": "cMsHBPEpo9zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import glob\n",
        "# import numpy as np\n",
        "\n",
        "# # Definição das funções de janela deslizante\n",
        "# def create_sliding_window(data, D, s):\n",
        "#     windows = []\n",
        "#     frame_numbers = []\n",
        "\n",
        "#     if s < 1:\n",
        "#         s = int(D * s)\n",
        "\n",
        "#     N = data.shape[0]  # Number of frames\n",
        "\n",
        "#     for start in range(0, N, s):\n",
        "#         end = start + D\n",
        "#         # Create a window only if there are enough data points\n",
        "#         if end <= N:\n",
        "#             window = data[start:end]\n",
        "#             windows.append(window)\n",
        "#             frame_numbers.append((start, end))\n",
        "\n",
        "#     windows = np.asarray(windows)\n",
        "#     frame_numbers = np.asarray(frame_numbers)\n",
        "\n",
        "#     output = {\"windows\": windows, \"frame_numbers\": frame_numbers}\n",
        "#     return output\n",
        "\n",
        "# def create_sliding_equal_sized_window(data, num_windows):\n",
        "#     windows = []\n",
        "#     frame_numbers = []\n",
        "\n",
        "#     N = data.shape[0]  # Number of frames\n",
        "\n",
        "#     # Calculate window size to evenly distribute frames across windows\n",
        "#     D = max(1, N // num_windows)\n",
        "\n",
        "#     for start in range(0, N, D):\n",
        "#         end = start + D\n",
        "#         # Adjust the end for the last window\n",
        "#         if end > N or (start == N - D and end < N):\n",
        "#             end = N\n",
        "\n",
        "#         window = data[start:end]\n",
        "#         windows.append(window)\n",
        "#         frame_numbers.append((start, end))\n",
        "\n",
        "#         # Break the loop after the last window\n",
        "#         if end == N:\n",
        "#             break\n",
        "\n",
        "#     windows = np.asarray(windows)\n",
        "#     frame_numbers = np.asarray(frame_numbers)\n",
        "\n",
        "#     output = {\"windows\": windows, \"frame_numbers\": frame_numbers}\n",
        "#     return output\n",
        "\n",
        "# # Função para normalizar os keypoints\n",
        "# def normalize_keypoints(keypoints_array):\n",
        "#     min_val = np.min(keypoints_array, axis=(1, 2, 3), keepdims=True)\n",
        "#     max_val = np.max(keypoints_array, axis=(1, 2, 3), keepdims=True)\n",
        "#     normalized_keypoints = (keypoints_array - min_val) / (max_val - min_val)\n",
        "#     return normalized_keypoints\n",
        "\n",
        "# # Funções para calcular a matriz de distância e vetor de características de distância\n",
        "# def calculate_distance_matrix(data):\n",
        "#     T, J, D = data.shape\n",
        "#     distance_matrices = np.zeros((T, J, J))\n",
        "#     flattened_vectors = []\n",
        "\n",
        "#     for t in range(T):\n",
        "#         for i in range(J):\n",
        "#             for j in range(J):\n",
        "#                 distance_matrices[t, i, j] = np.linalg.norm(data[t, i] - data[t, j])\n",
        "#         flattened_vectors.append(distance_feature_vector(distance_matrices[t]))\n",
        "\n",
        "#     return flattened_vectors\n",
        "\n",
        "# def distance_feature_vector(dist_matrix):\n",
        "#     upper_triangle = np.triu_indices(dist_matrix.shape[0], k=1)\n",
        "#     flattened_vector = dist_matrix[upper_triangle]\n",
        "#     return flattened_vector\n",
        "\n",
        "# def apply_features(array):\n",
        "#     array_of_features = []\n",
        "#     for data in array:\n",
        "#         flattened_vectors = calculate_distance_matrix(data)\n",
        "#         array_of_features.append(flattened_vectors)\n",
        "#     return array_of_features\n",
        "\n",
        "# # Carregar os keypoints e calcular as features\n",
        "# data_dir = '/content/Transfomer_keypoint/MediaPipe/treino'\n",
        "# output_dir = '/content/drive/MyDrive/Train_kp_features'\n",
        "\n",
        "# keypoints_list = []\n",
        "# labels_list = []\n",
        "# names_list = []\n",
        "\n",
        "# for class_folder in os.listdir(data_dir):\n",
        "#     class_path = os.path.join(data_dir, class_folder)\n",
        "\n",
        "#     for file_path in glob.glob(os.path.join(class_path, '*.npy')):\n",
        "#         keypoints = np.load(file_path, allow_pickle=True)\n",
        "#         keypoints_list.append(keypoints)\n",
        "#         labels_list.append(int(class_folder))\n",
        "#         names_list.append(os.path.basename(file_path).split('_')[0])  # Nome do bebê\n",
        "\n",
        "# keypoints_array = np.array(keypoints_list)  # (22, 900, 33, 2)\n",
        "# labels_array = np.array(labels_list)\n",
        "\n",
        "# # Normalizar os keypoints\n",
        "# keypoints_array_normalized = normalize_keypoints(keypoints_array)\n",
        "\n",
        "# # Aplicar as features nos keypoints normalizados\n",
        "# array_of_features = apply_features(keypoints_array_normalized)\n",
        "\n",
        "# # Aplicar janela deslizante nas features\n",
        "# D = 100  # Tamanho da janela (por exemplo, 100 frames)\n",
        "# s = 50   # Passo (por exemplo, 50 frames)\n",
        "# windowed_features = []\n",
        "\n",
        "# for features in array_of_features:\n",
        "#     output = create_sliding_window(np.array(features), D, s)\n",
        "#     windows = output[\"windows\"]\n",
        "#     windowed_features.append(windows)\n",
        "\n",
        "# # Salvar as features com os nomes dos bebês\n",
        "# if not os.path.exists(output_dir):\n",
        "#     os.makedirs(output_dir)\n",
        "\n",
        "# for features, label, name in zip(windowed_features, labels_array, names_list):\n",
        "#     feature_path = os.path.join(output_dir, f\"{label}/{name}_features.npy\")\n",
        "\n",
        "#     # Cria o diretório se não existir\n",
        "#     os.makedirs(os.path.dirname(feature_path), exist_ok=True)\n",
        "\n",
        "#     # Salva o arquivo\n",
        "#     np.save(feature_path, features)\n"
      ],
      "metadata": {
        "id": "P8TaoJ2BIKCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "# Definição das funções de janela deslizante\n",
        "def create_sliding_window(data, D, s):\n",
        "    windows = []\n",
        "    frame_numbers = []\n",
        "\n",
        "    if s < 1:\n",
        "        s = int(D * s)\n",
        "\n",
        "    N = data.shape[0]  # Number of frames\n",
        "\n",
        "    for start in range(0, N, s):\n",
        "        end = start + D\n",
        "        # Create a window only if there are enough data points\n",
        "        if end <= N:\n",
        "            window = data[start:end]\n",
        "            windows.append(window)\n",
        "            frame_numbers.append((start, end))\n",
        "\n",
        "    windows = np.asarray(windows)\n",
        "    frame_numbers = np.asarray(frame_numbers)\n",
        "\n",
        "    output = {\"windows\": windows, \"frame_numbers\": frame_numbers}\n",
        "    return output\n",
        "\n",
        "def create_sliding_equal_sized_window(data, num_windows):\n",
        "    windows = []\n",
        "    frame_numbers = []\n",
        "\n",
        "    N = data.shape[0]  # Number of frames\n",
        "\n",
        "    # Calculate window size to evenly distribute frames across windows\n",
        "    D = max(1, N // num_windows)\n",
        "\n",
        "    for start in range(0, N, D):\n",
        "        end = start + D\n",
        "        # Adjust the end for the last window\n",
        "        if end > N or (start == N - D and end < N):\n",
        "            end = N\n",
        "\n",
        "        window = data[start:end]\n",
        "        windows.append(window)\n",
        "        frame_numbers.append((start, end))\n",
        "\n",
        "        # Break the loop after the last window\n",
        "        if end == N:\n",
        "            break\n",
        "\n",
        "    windows = np.asarray(windows)\n",
        "    frame_numbers = np.asarray(frame_numbers)\n",
        "\n",
        "    output = {\"windows\": windows, \"frame_numbers\": frame_numbers}\n",
        "    return output\n",
        "\n",
        "# Função para normalizar os keypoints\n",
        "def normalize_keypoints(keypoints_array):\n",
        "    min_val = np.min(keypoints_array, axis=(1, 2, 3), keepdims=True)\n",
        "    max_val = np.max(keypoints_array, axis=(1, 2, 3), keepdims=True)\n",
        "    normalized_keypoints = (keypoints_array - min_val) / (max_val - min_val)\n",
        "    return normalized_keypoints\n",
        "\n",
        "# Funções para calcular a matriz de distância e vetor de características de distância\n",
        "def calculate_distance_matrix(data):\n",
        "    T, J, D = data.shape\n",
        "    distance_matrices = np.zeros((T, J, J))\n",
        "    flattened_vectors = []\n",
        "\n",
        "    for t in range(T):\n",
        "        for i in range(J):\n",
        "            for j in range(J):\n",
        "                distance_matrices[t, i, j] = np.linalg.norm(data[t, i] - data[t, j])\n",
        "        flattened_vectors.append(distance_feature_vector(distance_matrices[t]))\n",
        "\n",
        "    return flattened_vectors\n",
        "\n",
        "def distance_feature_vector(dist_matrix):\n",
        "    upper_triangle = np.triu_indices(dist_matrix.shape[0], k=1)\n",
        "    flattened_vector = dist_matrix[upper_triangle]\n",
        "    return flattened_vector\n",
        "\n",
        "def apply_features(array):\n",
        "    array_of_features = []\n",
        "    for data in array:\n",
        "        flattened_vectors = calculate_distance_matrix(data)\n",
        "        array_of_features.append(flattened_vectors)\n",
        "    return array_of_features\n",
        "\n",
        "# Carregar os keypoints e calcular as features\n",
        "data_dir = '/content/Transfomer_keypoint/MediaPipe/treino'\n",
        "output_dir = '/content/drive/Train_kp_features'\n",
        "\n",
        "keypoints_list = []\n",
        "labels_list = []\n",
        "names_list = []\n",
        "\n",
        "for class_folder in os.listdir(data_dir):\n",
        "    class_path = os.path.join(data_dir, class_folder)\n",
        "\n",
        "    for file_path in glob.glob(os.path.join(class_path, '*.npy')):\n",
        "        keypoints = np.load(file_path, allow_pickle=True)\n",
        "        keypoints_list.append(keypoints)\n",
        "        labels_list.append(int(class_folder))\n",
        "        names_list.append(os.path.basename(file_path).split('_')[0])  # Nome do bebê\n",
        "\n",
        "keypoints_array = np.array(keypoints_list)  # (22, 900, 33, 2)\n",
        "labels_array = np.array(labels_list)\n",
        "\n",
        "# Normalizar os keypoints\n",
        "keypoints_array_normalized = normalize_keypoints(keypoints_array)\n",
        "\n",
        "# Aplicar as features nos keypoints normalizados\n",
        "array_of_features = apply_features(keypoints_array_normalized)\n",
        "\n",
        "# Aplicar janela deslizante nas features\n",
        "D = 100  # Tamanho da janela (por exemplo, 100 frames)\n",
        "s = 50   # Passo (por exemplo, 50 frames)\n",
        "windowed_features = []\n",
        "\n",
        "for features in array_of_features:\n",
        "    output = create_sliding_window(np.array(features), D, s)\n",
        "    windows = output[\"windows\"]\n",
        "    windowed_features.append(windows)\n",
        "\n",
        "# Salvar as features com os nomes dos bebês\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "for features, label, name in zip(windowed_features, labels_array, names_list):\n",
        "    feature_path = os.path.join(output_dir, f\"{label}/{name}_features.npy\")\n",
        "\n",
        "    # Cria o diretório se não existir\n",
        "    os.makedirs(os.path.dirname(feature_path), exist_ok=True)\n",
        "\n",
        "    # Salva o arquivo\n",
        "    np.save(feature_path, features)\n"
      ],
      "metadata": {
        "id": "XDZCX1Wd1X9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aQ84hta3PTp",
        "outputId": "4678c47e-fe40-450b-a492-32490f49c90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17, 100, 528)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(windowed_features).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH2VMZyc4F4r",
        "outputId": "7c2a7de8-c9fc-4108-901b-752bf8613768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22, 17, 100, 528)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Suponha que windowed_features seja o array de janelas deslizantes com shape (22, 17, 100, 528)\n",
        "\n",
        "# Verificar o número total de frames incluídos em todas as janelas deslizantes\n",
        "total_frames = np.sum([window.shape[1] for window in windowed_features])\n",
        "\n",
        "# Inicializar um array para armazenar todos os frames concatenados\n",
        "concatenated_frames = np.zeros((22, total_frames, 528))\n",
        "\n",
        "# # Índice de início para adicionar frames ao array concatenado\n",
        "# start_index = 0\n",
        "\n",
        "# # Loop sobre cada vídeo\n",
        "# for video_idx, video_windows in enumerate(windowed_features):\n",
        "#     # Loop sobre cada janela deslizante do vídeo\n",
        "#     for window in video_windows:\n",
        "#         # Determinar o número de frames na janela deslizante\n",
        "#         num_frames = window.shape[1]\n",
        "#         # Adicionar os frames da janela deslizante ao array concatenado\n",
        "#         concatenated_frames[video_idx, start_index:start_index+num_frames, :] = window\n",
        "#         # Atualizar o índice de início para a próxima janela deslizante\n",
        "#         start_index += num_frames\n",
        "\n",
        "# Verificar o shape do array concatenado\n",
        "print(concatenated_frames.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "panTUsm07wpw",
        "outputId": "07850e41-5b27-4e45-b4d8-c5e5cffcb8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22, 2200, 528)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "data_dir = '/content/Transfomer_keypoint/MediaPipe/teste'\n",
        "output_dir = '/content/drive/MyDrive/Test_kp_features'\n",
        "\n",
        "keypoints_list = []\n",
        "labels_list = []\n",
        "names_list = []\n",
        "\n",
        "for class_folder in os.listdir(data_dir):\n",
        "    class_path = os.path.join(data_dir, class_folder)\n",
        "\n",
        "    for file_path in glob.glob(os.path.join(class_path, '*.npy')):\n",
        "        keypoints = np.load(file_path, allow_pickle=True)\n",
        "        keypoints_list.append(keypoints)\n",
        "        labels_list.append(int(class_folder))\n",
        "        names_list.append(os.path.basename(file_path).split('_')[0])  # Nome do bebê\n",
        "\n",
        "keypoints_array = np.array(keypoints_list)\n",
        "labels_array = np.array(labels_list)\n",
        "\n",
        "# Função para normalizar os keypoints\n",
        "def normalize_keypoints(keypoints_array):\n",
        "    min_val = np.min(keypoints_array, axis=(1, 2, 3), keepdims=True)\n",
        "    max_val = np.max(keypoints_array, axis=(1, 2, 3), keepdims=True)\n",
        "    normalized_keypoints = (keypoints_array - min_val) / (max_val - min_val)\n",
        "    return normalized_keypoints\n",
        "\n",
        "keypoints_array_normalized = normalize_keypoints(keypoints_array)\n",
        "\n",
        "# Funções para calcular a matriz de distância e vetor de características de distância\n",
        "def calculate_distance_matrix(data):\n",
        "    T, J, D = data.shape\n",
        "    distance_matrices = np.zeros((T, J, J))\n",
        "    flattened_vectors = []\n",
        "\n",
        "    for t in range(T):\n",
        "        for i in range(J):\n",
        "            for j in range(J):\n",
        "                distance_matrices[t, i, j] = np.linalg.norm(data[t, i] - data[t, j])\n",
        "        flattened_vectors.append(distance_feature_vector(distance_matrices[t]))\n",
        "\n",
        "    return flattened_vectors\n",
        "\n",
        "def distance_feature_vector(dist_matrix):\n",
        "    upper_triangle = np.triu_indices(dist_matrix.shape[0], k=1)\n",
        "    flattened_vector = dist_matrix[upper_triangle]\n",
        "    return flattened_vector\n",
        "\n",
        "def apply_features(array):\n",
        "    array_of_features = []\n",
        "    for data in array:\n",
        "        flattened_vectors = calculate_distance_matrix(data)\n",
        "        array_of_features.append(flattened_vectors)\n",
        "    return array_of_features\n",
        "\n",
        "# Aplicar as features nos keypoints normalizados\n",
        "array_of_features = apply_features(keypoints_array_normalized)\n",
        "\n",
        "# Salvar as features com os nomes dos bebês\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "for features, label, name in zip(array_of_features, labels_array, names_list):\n",
        "    feature_path = os.path.join(output_dir, f\"{label}/{name}_features.npy\")\n",
        "\n",
        "    # Cria o diretório se não existir\n",
        "    os.makedirs(os.path.dirname(feature_path), exist_ok=True)\n",
        "\n",
        "    # Salva o arquivo\n",
        "    np.save(feature_path, features)\n"
      ],
      "metadata": {
        "id": "eJKxmntNRyEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Token de acesso pessoal do GitHub\n",
        "\"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\"\n",
        "\n",
        "# Clone o repositório do GitHub usando o token\n",
        "!git clone https://{token}@github.com/Nibi2003/Transfomer_keypoint.git\n",
        "\n",
        "# Caminhos das pastas no Google Drive\n",
        "train_folder_path = \"/content/drive/MyDrive/Train_kp_features\"\n",
        "test_folder_path = \"/content/drive/MyDrive/Test_kp_features\"\n",
        "\n",
        "# Caminho do repositório clonado\n",
        "repo_path = \"/content/Transfomer_keypoint\"\n",
        "\n",
        "# Mover as pastas\n",
        "shutil.move(train_folder_path, repo_path)\n",
        "shutil.move(test_folder_path, repo_path)\n",
        "\n",
        "# Configurar as credenciais do Git\n",
        "!git config --global user.email \"beatrizaguiar0202@gmail.com\"\n",
        "!git config --global user.name \"Nibi2003\"\n",
        "\n",
        "# Entrar no diretório clonado\n",
        "os.chdir(\"/content/Transfomer_keypoint\")\n",
        "\n",
        "# Adicionar todos os arquivos, fazer commit e enviar para o GitHub\n",
        "!git add .\n",
        "!git commit -m \"Adiciona pastas com features de keypoints do treino e teste\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0wXSpO9d2md",
        "outputId": "41ccf746-bcc9-4f8b-8ce0-1673cf3c2b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'Transfomer_keypoint' already exists and is not an empty directory.\n",
            "[main 53672d3] Adiciona pastas com features de keypoints do treino e teste\n",
            " 38 files changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 Test_kp_features/0/bebe07-1_features.npy\n",
            " create mode 100644 Test_kp_features/0/bebe07-2_features.npy\n",
            " create mode 100644 Test_kp_features/0/bebe19_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe09-1_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe09-2_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe09-4_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe11-1_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe11-2_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe11-3_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe15-1_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe15-2_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe15-3_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe15-4_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe20-1_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe20-2_features.npy\n",
            " create mode 100644 Test_kp_features/1/bebe20-3_features.npy\n",
            " create mode 100644 Train_kp_features/0/bebe02-1_features.npy\n",
            " create mode 100644 Train_kp_features/0/bebe02-2_features.npy\n",
            " create mode 100644 Train_kp_features/0/bebe02-3_features.npy\n",
            " create mode 100644 Train_kp_features/0/bebe02-4_features.npy\n",
            " create mode 100644 Train_kp_features/0/bebe05-1_features.npy\n",
            " create mode 100644 Train_kp_features/0/bebe05-2_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe03_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe04_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe08_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe12_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe14-1_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe14-2_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe16-1_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe16-2_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe16-3_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe16-4_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe16-5_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe17-1_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe17-2_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe18_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe21_features.npy\n",
            " create mode 100644 Train_kp_features/1/bebe22_features.npy\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar todos os arquivos, fazer commit e enviar para o GitHub\n",
        "!git add .\n",
        "!git commit -m \"Adiciona pastas com features de keypoints do treino e teste\"\n",
        "!git push https://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@github.com/Nibi2003/Transfomer_keypoint.git main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Bbl_3IJh8qb",
        "outputId": "15e12176-53ae-4d45-f6d3-2b2ea16ee78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Enumerating objects: 47, done.\n",
            "Counting objects: 100% (47/47), done.\n",
            "Delta compression using up to 16 threads\n",
            "Compressing objects: 100% (46/46), done.\n",
            "Writing objects: 100% (46/46), 129.95 MiB | 11.49 MiB/s, done.\n",
            "Total 46 (delta 0), reused 0 (delta 0), pack-reused 0\n",
            "To https://github.com/Nibi2003/Transfomer_keypoint.git\n",
            "   93aa1a7..53672d3  main -> main\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}